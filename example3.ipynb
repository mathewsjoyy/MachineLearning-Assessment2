{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Assessment 2\n",
    "\n",
    "Through the following notebook, you will be tasked with **implementing** two different classification approaches: **k Nearest Neighbours** and **Decision Trees**. You will apply these to two different datasets, evaluate the produced models and analyse their performance.\n",
    "\n",
    "This will be done through several different tasks and sub-tasks:\n",
    "- [Dataset](#Dataset)\n",
    "    - [Task 1: Dataset statistics **(10\\%)**](#Task-1---Dataset-statistics)\n",
    "- [k Nearest Neigbours](#k-Nearest-Neigbours)\n",
    "    - [Task 2.1: Euclidean distance **(10\\%)**](#Task-2.1---Euclidean-distance)\n",
    "    - [Task 2.2: kNN classifier **(20\\%)**](#Task-2.2---kNN-classifier)\n",
    "- [Decision Trees](#Decision-Trees)\n",
    "    - [Task 3.1: Entropy and Information Gain **(10\\%)**](#Task-3.1---Entropy-and-Information-Gain)\n",
    "    - [Task 3.2: Decision Tree classifier **(30\\%)**](#Task-3.2---Decision-Tree-classifier)\n",
    "- [Model evaluation and analysis](#Model-evaluation-and-analysis)\n",
    "    - [Task 4.1: Evaluation **(10\\%)**](#Task-4.1---Evaluation)\n",
    "    - [Task 4.2: Analysis **(10\\%)**](#Task-4.2---Analysis)\n",
    "\n",
    "**Note:** The (%) noted above are out of 100; this will be scaled down to **maximum of 70 marks** for the assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "For this assessment, you will be working with two datasets:\n",
    "- A [numeric-only](#Numerical-data) dataset (crystal systems of Li-ion batteries)\n",
    "- A dataset with [mixed numeric and categorical](#Categorical-data) features (forest cover)\n",
    "\n",
    "For developing your solutions, **you have only been provided with a portion of the samples from each of the dataset** (70% of the [numeric-only](#Numerical-data) and 50% of the [mixed numeric and categorical](#Categorical-data) data). These will be in **identical format** to the full datasets used for evaluating your solutions (there will just be more samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical data\n",
    "\n",
    "The main part of the assessment will be done on the dataset containing only numerical features describing the physical and chemical properties of the Li-ion battery, which can be classified on the basis of their crystal system. Three major classes of crystal systems are: _monoclinic_, _orthorhombic_ and _triclinic_. (The dataset for this assessment has been adapted from the full dataset which can be found [here](https://www.kaggle.com/datasets/divyansh22/crystal-system-properties-for-liion-batteries\n",
    "\n",
    "Each sample corresponds to the properties of a battery, and consists of following features:\n",
    "\n",
    "| Feature Name      | Value | Description |\n",
    "| :---------------- | :----- | ----------- |\n",
    "| `Formation Energy`       | `float`: eV | Formation energy of the material. |\n",
    "| `E Above Hull` | `float`: eV | Energy of decomposition of material into most stable ones. |\n",
    "| `Band Gap` | `float`: eV | Band gap. |\n",
    "| `Nsites` | `int`: count | Number of atoms in the unit cell of the crystal. |\n",
    "| `Density` | `float`: gm/cc | The density of bulk crystalline materials. |\n",
    "| `Volume` | `float` | The unit cell volume of the material. |\n",
    "\n",
    "The goal for the assessment is to predict whether the crystal system of the battery is _monoclinic_, _orthorhombic_ or _triclinic_, which provides a classification for each sample:\n",
    "\n",
    "| Class      | Value | Description |\n",
    "| :---------------- | :----- | ----------- |\n",
    "| `Crystal System`  | `string`: class designation | Class of the crystal system (three different values). |\n",
    "\n",
    "\n",
    "This dataset will be used for the developmet and testing of both the [kNN](#k-Nearest-Neigbours) and [Decision Tree](#Decision-Trees) classifier, as well as for the [evaluation](#Task-4.1---Evaluation) of both of the classification approaches.\n",
    "\n",
    "The following cell loads the dataset, and splits the samples randomly, using  $80\\%$ of samples for training and $20\\%$ for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset consists of 339 samples\n",
      "The numerical data loaded consists of following columns:\n",
      "\tColumn 0: Formation Energy\n",
      "\tColumn 1: E Above Hull\n",
      "\tColumn 2: Band Gap\n",
      "\tColumn 3: Nsites\n",
      "\tColumn 4: Density\n",
      "\tColumn 5: Volume\n",
      "\tColumn 6: Crystal System\n",
      "An example sample:\n",
      "\tFeature 0: Formation Energy=-2.699\n",
      "\tFeature 1: E Above Hull=0.006\n",
      "\tFeature 2: Band Gap=3.462\n",
      "\tFeature 3: Nsites=16\n",
      "\tFeature 4: Density=2.9930000000000003\n",
      "\tFeature 5: Volume=178.513\n",
      "\tClass (Family): monoclinic\n",
      "The training set consists of 271 samples and 271 associated ground truth classes\n",
      "The test set consists of 68 samples and 68 associated ground truth classes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-2.69900e+00,  6.00000e-03,  3.46200e+00,  1.60000e+01,\n",
       "         2.99300e+00,  1.78513e+02],\n",
       "       [-2.69600e+00,  8.00000e-03,  2.87900e+00,  3.20000e+01,\n",
       "         2.92600e+00,  3.65272e+02],\n",
       "       [-2.77500e+00,  1.20000e-02,  3.65300e+00,  2.80000e+01,\n",
       "         2.76100e+00,  3.01775e+02],\n",
       "       ...,\n",
       "       [-2.52900e+00,  8.20000e-02,  1.76000e-01,  3.50000e+01,\n",
       "         2.94000e+00,  4.28648e+02],\n",
       "       [-2.34800e+00,  8.70000e-02,  1.33300e+00,  1.40000e+01,\n",
       "         2.45100e+00,  2.14044e+02],\n",
       "       [-2.40600e+00,  9.00000e-02,  3.23000e-01,  1.50000e+01,\n",
       "         3.04300e+00,  1.76207e+02]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import count\n",
    "\n",
    "numerical_data = pd.read_csv(r'batteries.csv')\n",
    "\n",
    "print(\"The dataset consists of {} samples\".format(len(numerical_data)))\n",
    "print(\"The numerical data loaded consists of following columns:\\n{}\".format(\n",
    "    \"\\n\".join([\"\\tColumn {}: {}\".format(i, x) for i, x in enumerate(numerical_data.columns)])))\n",
    "print(\"An example sample:\\n{}\".format(\n",
    "    \"\\n\".join([\"\\tFeature {}: {}={}\".format(i, x, v) for i, (x, v) in \n",
    "               enumerate(zip(numerical_data.columns, numerical_data.loc[0, :])) if not x == 'Crystal System'])))\n",
    "print('\\tClass (Family): {}'.format(numerical_data.loc[0, 'Crystal System']))\n",
    "\n",
    "# We split the dataset into features and the target class, using the 'Family' column as the target:\n",
    "X_nd = numerical_data.loc[:, numerical_data.columns!='Crystal System'].values\n",
    "y_nd = numerical_data['Crystal System'].values\n",
    "\n",
    "# We further split the dataset into a training and testing set\n",
    "X_nd_train, X_nd_test, y_nd_train, y_nd_test = train_test_split(X_nd, y_nd, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(\"The training set consists of {} samples and {} associated ground truth classes\".format(len(X_nd_train),\n",
    "                                                                                             len(y_nd_train)))\n",
    "print(\"The test set consists of {} samples and {} associated ground truth classes\".format(len(X_nd_test),\n",
    "                                                                                             len(y_nd_test)))\n",
    "\n",
    "X_nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical data\n",
    "\n",
    "The second dataset for this assessment contains a mix of numerical and categorical features, with the goal of predicting the forest cover type. The data used in this assessment is adapted from a full dataset provided [here](https://archive.ics.uci.edu/ml/datasets/Covertype) (Jock A. Blackard and Colorado State University).\n",
    "\n",
    "Each sample corresponds to a 30x30 meter cell, and consists of cartographic variables only (i.e. it does not rely on any remotely sensed imaging data), derived from from US Geological Survey (USGS) and USFS data. Each sample consists of the following features (categorical features can be distinguished by being encoded as a string rather tha a numer):\n",
    "\n",
    "| Feature Name      | Value | Description |\n",
    "| :---------------- | :----- | ----------- |\n",
    "| `Elevation`       | `float`: kilometers | Elevation |\n",
    "| `Aspect`   | `int`: degrees azimut | Aspect in degreez azimuth |\n",
    "| `Slope`      | `int`: degrees | Slope in degrees |\n",
    "| `Horizontal_Distance_To_Hydrology`   | `float`: kilometers | Horiz. distance to nearest surface water feature        |\n",
    "| `Vertical_Distance_To_Hydrology`   | `float`: kilometers | Vert. distance to nearest surface water feature        |\n",
    "| `Horizontal_Distance_To_Roadways`     | `float`: kilometers | Hor. distance to nearest roadway       |\n",
    "| `Hillshade_9am`   |`int`: $0 \\dots 255 $|  Hillshade index at 9am, summer solstice        |\n",
    "| `Hillshade_Noon`      |`int`: $0 \\dots 255 $| Hillshade index at noon, summer solstice       |\n",
    "| `Hillshade_3pm`   |`int`: $0 \\dots 255 $| Hillshade index at 3pm, summer solstice        |\n",
    "| `Horizontal_Distance_To_Fire_Points`  | `float`: kilometers | Horiz. distance to nearest wildfire ignition point        |\n",
    "| `Wilderness_Area`   | `string`: name | Wilderness area name (4 different values)       |\n",
    "| `Soil_Type`   |`string`: code| Soil type code (40 different values)       |\n",
    "\n",
    "The goal of this dataset is to predict the forrest cover type for each 30x30 meter cell. A class, corresponding to the forest cover type, is associated to each sample:\n",
    "\n",
    "| Class      | Value | Description |\n",
    "| :---------------- | :----- | ----------- |\n",
    "| `Cover_Type`       | `string`: name | Forest cover type designation (7 different values). |\n",
    "\n",
    "\n",
    "**Note:** Tackling the categorical dataset is a **stretch task** for this assessment. It will be used in the development and testing of the [Decision Tree](#Decision-Trees) classifier, as well as for their [evaluation](#Task-4.1---Evaluation). Tackling this data will **require you to implement a** `DecisionTree` **from scratch**, as `sklearn` **does not provide this functionality**.\n",
    "\n",
    "The following cell loads the dataset, and splits the samples randomly, using  $80\\%$ of samples for training and $20\\%$ for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'forestcover.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Mathews\\OneDrive\\Documents\\BSc_Computer_Science_Files\\Year_3\\Machine_Learning\\MathewsJoy_MachineLearning_Assessment2\\example3.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Mathews/OneDrive/Documents/BSc_Computer_Science_Files/Year_3/Machine_Learning/MathewsJoy_MachineLearning_Assessment2/example3.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m categorical_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mforestcover.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Mathews/OneDrive/Documents/BSc_Computer_Science_Files/Year_3/Machine_Learning/MathewsJoy_MachineLearning_Assessment2/example3.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe dataset consists of \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m samples\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mlen\u001b[39m(categorical_data)))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Mathews/OneDrive/Documents/BSc_Computer_Science_Files/Year_3/Machine_Learning/MathewsJoy_MachineLearning_Assessment2/example3.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe numerical data loaded consists of following columns:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Mathews/OneDrive/Documents/BSc_Computer_Science_Files/Year_3/Machine_Learning/MathewsJoy_MachineLearning_Assessment2/example3.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mColumn \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(i, x) \u001b[39mfor\u001b[39;00m i, x \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(categorical_data\u001b[39m.\u001b[39mcolumns)])))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'forestcover.csv'"
     ]
    }
   ],
   "source": [
    "categorical_data = pd.read_csv(r'forestcover.csv')\n",
    "\n",
    "print(\"The dataset consists of {} samples\".format(len(categorical_data)))\n",
    "print(\"The numerical data loaded consists of following columns:\\n{}\".format(\n",
    "    \"\\n\".join([\"\\tColumn {}: {}\".format(i, x) for i, x in enumerate(categorical_data.columns)])))\n",
    "print(\"An example sample:\\n{}\".format(\n",
    "    \"\\n\".join([\"\\tFeature {}: {}={}\".format(i, x, v) for i, (x, v) in \n",
    "               enumerate(zip(categorical_data.columns, categorical_data.loc[0, :])) if not x == 'Cover_Type'])))\n",
    "print('\\tClass (Cover_Type): {}'.format(categorical_data.loc[0, 'Cover_Type']))\n",
    "\n",
    "# We split the dataset into features and the target class, using the 'Cover_Type' column as the target:\n",
    "X_cd = categorical_data.loc[:, categorical_data.columns!='Cover_Type'].values\n",
    "y_cd = categorical_data['Cover_Type'].values\n",
    "\n",
    "\n",
    "# We further split the dataset into a training and testing set\n",
    "X_cd_train, X_cd_test, y_cd_train, y_cd_test = train_test_split(X_cd, y_cd, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(\"The training set consists of {} samples and {} associated ground truth classes\".format(len(X_cd_train),\n",
    "                                                                                             len(y_cd_train)))\n",
    "print(\"The test set consists of {} samples and {} associated ground truth classes\".format(len(X_cd_test),\n",
    "                                                                                             len(y_cd_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Dataset statistics\n",
    "#### 10% marks\n",
    "\n",
    "To handle the data for the classification tasks, implement functions that will assist in querying some basic information about the dataset you are handling.\n",
    "\n",
    "Given a set of M samples $\\mathbf{x} = \\{\\mathbf{x}_i\\} \\forall i=1..M$ with n features each $\\mathbf{x}_i = \\{x_{1,i}, \\dots, x_{n,i}\\}$, and the corresponding ground truth labels $\\mathbf{y} = \\{y_i\\} \\forall i=1..M$, implement two functions:\n",
    "\n",
    "- `class_probabilities(y)` : calcualtes the class probabilities from the list of ground truth labels\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `y`: The list of ground truth labels for a dataset<br>\n",
    "    \n",
    "    *Returns:*<br>\n",
    "    A dictionary of class labels and their probabilities (i.e. the frequency of that class in the dataset)\n",
    "\n",
    "    *Example* :\n",
    "    ```python\n",
    "    y = [1, 0, 0, 0, 1, 2, 1, 1, 2, 1]\n",
    "    print(class_probabilities(y))\n",
    "    ```\n",
    "    *Example output*:<br>\n",
    "    `{0: 0.3, 1: 0.5, 2: 0.2}`\n",
    "    \n",
    "    *Note:* Python dictionaries are unordered, so running this example might result in a different order of keys in the output, for example: `{2: 0.2, 0: 0.3, 1: 0.5}`<br><br>\n",
    "   \n",
    "- `most_common_class` : finds the most common class from the list of ground truth class labels.\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `y`: the list of ground truth labels for a dataset<br>\n",
    "    \n",
    "    *Returns:*<br>\n",
    "    the label of the most common class represented in the dataset.\n",
    "    \n",
    "    *Example*:\n",
    "    ```python\n",
    "    y = [1, 0, 0, 0, 1, 2, 1, 1, 2, 1]\n",
    "    print(most_common_class(y))\n",
    "    ```\n",
    "    *Example output*:<br>\n",
    "    `1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOLUTION CELLS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_probabilities(y):\n",
    "    # List comprehension to initialise the labels in the dictionary.\n",
    "    # This saves having to check if the value exists later.\n",
    "    frequency = dict([(label,0) for label in np.unique(y)])\n",
    "    # Count the frequency.\n",
    "    for item in y:\n",
    "        frequency[item] += 1\n",
    "    # Make all of the values a frequency between 0-1.\n",
    "    for item in frequency:\n",
    "        frequency[item] /= len(y)\n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_class(y):\n",
    "    p = class_probabilities(y)\n",
    "    # Sort by the values and return the most common.\n",
    "    return max(p, key=p.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING CELLS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All unique class labels and counts from numerical-only dataset: monoclinic: 139 orthorhombic: 128 triclinic: 72\n",
      "All classes and their probabilities:\n",
      "\tmonoclinic: 0.41002949852507375\n",
      "\torthorhombic: 0.3775811209439528\n",
      "\ttriclinic: 0.21238938053097345\n",
      "Most common class in the numerical-only dataset: monoclinic\n",
      "\n",
      "\n",
      "All unique class labels for the numerical-only training set: monoclinic: 106 orthorhombic: 106 triclinic: 59\n",
      "All classes and their probabilities (num-only training set):\n",
      "\tmonoclinic: 0.39114391143911437\n",
      "\torthorhombic: 0.39114391143911437\n",
      "\ttriclinic: 0.2177121771217712\n",
      "Most common class in the num-only training set: monoclinic\n",
      "\n",
      "\n",
      "All unique class labels for the numerical-only testing set: monoclinic: 33 orthorhombic: 22 triclinic: 13\n",
      "All classes and their probabilities (num-only tests set):\n",
      "\tmonoclinic: 0.4852941176470588\n",
      "\torthorhombic: 0.3235294117647059\n",
      "\ttriclinic: 0.19117647058823528\n",
      "Most common class in the num-only test set: monoclinic\n",
      "\n",
      "\n",
      "All class labels for a toy set: [1, 0, 0, 0, 1, 2, 1, 1, 2, 1]\n",
      "All classses and their probabilities for the toy set:\n",
      "\t0: 0.3\n",
      "\t1: 0.5\n",
      "\t2: 0.2\n",
      "Most common class in the toy set: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_cd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Mathews\\OneDrive\\Documents\\BSc_Computer_Science_Files\\Year_3\\Machine_Learning\\MathewsJoy_MachineLearning_Assessment2\\example3.ipynb Cell 13\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mathews/OneDrive/Documents/BSc_Computer_Science_Files/Year_3/Machine_Learning/MathewsJoy_MachineLearning_Assessment2/example3.ipynb#X15sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMost common class in the toy set: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(most_common_class(y_test)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mathews/OneDrive/Documents/BSc_Computer_Science_Files/Year_3/Machine_Learning/MathewsJoy_MachineLearning_Assessment2/example3.ipynb#X15sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mathews/OneDrive/Documents/BSc_Computer_Science_Files/Year_3/Machine_Learning/MathewsJoy_MachineLearning_Assessment2/example3.ipynb#X15sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAll classes and their probabilities from the categorical dataset:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Mathews/OneDrive/Documents/BSc_Computer_Science_Files/Year_3/Machine_Learning/MathewsJoy_MachineLearning_Assessment2/example3.ipynb#X15sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(c, p) \u001b[39mfor\u001b[39;00m c, p \u001b[39min\u001b[39;00m class_probabilities(y_cd)\u001b[39m.\u001b[39mitems()])))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mathews/OneDrive/Documents/BSc_Computer_Science_Files/Year_3/Machine_Learning/MathewsJoy_MachineLearning_Assessment2/example3.ipynb#X15sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMost common class in the categorical dataset: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(most_common_class(y_cd)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_cd' is not defined"
     ]
    }
   ],
   "source": [
    "unq, cnt = np.unique(y_nd, return_counts=True)\n",
    "print(\"All unique class labels and counts from numerical-only dataset: {}\".format(\n",
    "    ' '.join(['{}: {}'.format(v,c) for v, c in zip(unq, cnt)])))\n",
    "print(\"All classes and their probabilities:\\n{}\".format(\n",
    "    \"\\n\".join([\"\\t{}: {}\".format(c, p) for c, p in class_probabilities(y_nd).items()])))\n",
    "print(\"Most common class in the numerical-only dataset: {}\".format(most_common_class(y_nd)))\n",
    "print(\"\\n\")\n",
    "\n",
    "unq, cnt = np.unique(y_nd_train, return_counts=True)\n",
    "print(\"All unique class labels for the numerical-only training set: {}\".format(\n",
    "    ' '.join(['{}: {}'.format(v,c) for v, c in zip(unq, cnt)])))\n",
    "print(\"All classes and their probabilities (num-only training set):\\n{}\".format(\n",
    "    \"\\n\".join([\"\\t{}: {}\".format(c, p) for c, p in class_probabilities(y_nd_train).items()])))\n",
    "print(\"Most common class in the num-only training set: {}\".format(most_common_class(y_nd_train)))\n",
    "print(\"\\n\")\n",
    "\n",
    "unq, cnt = np.unique(y_nd_test, return_counts=True)\n",
    "print(\"All unique class labels for the numerical-only testing set: {}\".format(\n",
    "    ' '.join(['{}: {}'.format(v,c) for v, c in zip(unq, cnt)])))\n",
    "print(\"All classes and their probabilities (num-only tests set):\\n{}\".format(\n",
    "    \"\\n\".join([\"\\t{}: {}\".format(c, p) for c, p in class_probabilities(y_nd_test).items()])))\n",
    "print(\"Most common class in the num-only test set: {}\".format(most_common_class(y_nd_test)))\n",
    "print(\"\\n\")\n",
    "\n",
    "y_test = [1, 0, 0, 0, 1, 2, 1, 1, 2, 1]\n",
    "print(\"All class labels for a toy set: {}\".format(y_test))\n",
    "print(\"All classses and their probabilities for the toy set:\\n{}\".format(\n",
    "    \"\\n\".join([\"\\t{}: {}\".format(c, p) for c, p in class_probabilities(y_test).items()])))\n",
    "print(\"Most common class in the toy set: {}\".format(most_common_class(y_test)))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"All classes and their probabilities from the categorical dataset:\\n{}\".format(\n",
    "    \"\\n\".join([\"\\t{}: {:.3f}\".format(c, p) for c, p in class_probabilities(y_cd).items()])))\n",
    "print(\"Most common class in the categorical dataset: {}\".format(most_common_class(y_cd)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k Nearest Neighbours\n",
    "\n",
    "For the first part of the assessment, you are required to implement **k Nearest Neigbours**. A key concept for kNN (and many different machine learning algorithms) is that of **distance**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1 - Euclidean distance\n",
    "#### 10% marks\n",
    "\n",
    "One of the most commonly used distance metrics is the Euclidean distance. The Euclidean distance between two points in the Euclidean space (also known as $L_2$ norm) is defined as the length of the line segment between those two points. For example, if we have two points in 2D space (i.e. two samples consisting of two features), $\\mathbf{x}_0 = \\{x_{0,0}, x_{0,1}\\}$ and $\\mathbf{x}_1 = \\{x_{1,0}, x_{1,1}\\}$, we can calculate the distance as:\n",
    "\n",
    "\\begin{equation*}\n",
    "d_{\\texttt{Euclidean}} = \\sqrt{(x_{0,0} - x_{1,0})^2 + (x_{0,1} - x_{1,1})^2}\n",
    "\\end{equation*}\n",
    "\n",
    "In other words, we need to calculate the difference between the first features of the two samples, the difference between the second features of the two samples, then square each of the differences, sum those squares, and calculate the square root of the resulting sum.\n",
    "\n",
    "In general, when we are dealing with points in nD space (corresponding to samples with n features) of the form $\\mathbf{x}_i = \\{x_{0,i}, x_{1,i}, \\dots, x_{n,i}\\}$, the procedure is very similar. To calculade the Euclidean disatnce, you need to calculate the difference between the corresponding features of two samples, square each of the differences, and calculate the square root of the resulting sum:\n",
    "\n",
    "\\begin{equation*}\n",
    "d_{\\texttt{Euclidean}} = \\sqrt{\\sum_i{(x_{0,i} - x_{1,i})^2}}\n",
    "\\end{equation*}\n",
    "\n",
    "Implement the Euclidean distance as a Python function:\n",
    "- `euclidean_distance`: calculates the Euclidean distance between two n-dimensional samples\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `x1`: An n-dimensional sample. This either a list of length $n$, or a `numpy.array` of dimensions `(n,)`<br>\n",
    "    `x2`: An n-dimensional sample. This either a list of length $n$, or a `numpy.array` of dimensions `(n,)`<br>\n",
    "\n",
    "    *Returns*<br>\n",
    "    The Euclidean distance between `x1` and `x2`.<br>\n",
    "    \n",
    "    *Example:*\n",
    "\n",
    "    ```python\n",
    "    x1 = [7, -1]\n",
    "    x2 = [4, 3]\n",
    "    print(euclidean_distance(x1, x2)\n",
    "    ```\n",
    "    *Example output:*<br>\n",
    "    `5.0`\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOLUTION CELL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x1, x2):\n",
    "    return np.linalg.norm(np.array(x1) - np.array(x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING CELL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance between [7, -1] (2D) and [4, 3] (2D) is 5.0\n",
      "Euclidean distance between [1, 2] (2D) and [3, 4] (2D) is 2.828\n",
      "Euclidean distance between [4.2, 3.6, 1.0] (3D) and [5.7, 2.8, -1.5] (3D) is 3.023\n",
      "Euclidean distance between [0.37609582 0.82483045 0.70420319 0.38161809 0.14919889 0.86671402\n",
      " 0.47573453 0.42214756 0.84100029 0.16663854 0.52965663 0.23235015\n",
      " 0.85555256 0.01426005 0.66821176 0.47575985 0.33032883 0.40306689\n",
      " 0.86143817 0.01562122] (20D) and [0.88528973 0.70028312 0.76767396 0.72473002 0.06917089 0.5264588\n",
      " 0.09160981 0.21179682 0.27149632 0.01738076 0.09012757 0.87895167\n",
      " 0.20115469 0.68946825 0.06914127 0.5830926  0.00684563 0.65516413\n",
      " 0.50534487 0.40949215] (20D) is 1.837\n"
     ]
    }
   ],
   "source": [
    "a = [7, -1]\n",
    "b = [4, 3]\n",
    "print(\"Euclidean distance between {} ({}D) and {} ({}D) is {}\".format(\n",
    "    a, len(a), b, len(b), euclidean_distance(a,b)))\n",
    "a = [1, 2]\n",
    "b = [3, 4]\n",
    "print(\"Euclidean distance between {} ({}D) and {} ({}D) is {:.3f}\".format(\n",
    "    a, len(a), b, len(b), euclidean_distance(a,b)))\n",
    "a = [4.2, 3.6, 1.0]\n",
    "b = [5.7, 2.8, -1.5]\n",
    "print(\"Euclidean distance between {} ({}D) and {} ({}D) is {:.3f}\".format(\n",
    "    a, len(a), b, len(b), euclidean_distance(a,b)))\n",
    "a = np.random.rand(20)\n",
    "b = np.random.rand(20)\n",
    "print(\"Euclidean distance between {} ({}D) and {} ({}D) is {:.3f}\".format(\n",
    "    a, len(a), b, len(b), euclidean_distance(a,b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2 - kNN classifier\n",
    "#### 20% marks\n",
    "\n",
    "K nearest neighbours classifier will predict the class of a sample based on the class label of its $k$ nearest neigbours, according to a given distance metric. Implement `kNN` classifier which works on samples with numerical features, and relies on the Euclidean distance, as a Python class implementing the following member functions:\n",
    "\n",
    "- `__init__(self, k = 5, distance = euclidean_distance)`: class constructor\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `k` : The number of neigbours to be considered by the classification model <br>\n",
    "    `distance`: Tunction which is used to calculate the distance between samples (you will use the Euclidean distance implemented in the previous task)<br><br>\n",
    "    \n",
    "- `fit(self, X, y)`: member function used to train the classifier (fit the model to the data)\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `X`: The dataset samples. This is either a list of $M$ lists of length $n$, or a `numpy.array` of dimensions `(M, n)`<br>\n",
    "    `y`: The dataset labels. This is either a list of length $M$, or a `numpy.array` of dimensions `(M,)`<br><br>\n",
    "    \n",
    "    *Returns:*<br>\n",
    "    The trained classifier model.<br><br>\n",
    "    \n",
    "- `predict(self, X)`: member function used to predict the classes of samples `X`\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `X`: The samples for which to predict a class. If this is a single sample, then `X` is either a list of length $n$, or a `numpy.array` of dimensions `(n,)`. If this is a set of samples, then `X` is either a list of $M$ lists of length $n$, or a `numpy.array` of dimensions `(M, N)`<br>\n",
    "    \n",
    "    *Returns:*<br>\n",
    "    Predicted class for the samples of X. If `X` was a single sample, then the output is a single class label. If `X` was a set of samples, then the output is a `numpy.array` of dimensions `(n,`)<br>\n",
    "    \n",
    "    *Note:*<br>\n",
    "    The provided code outline already handles the case where `X` is a set of samples (by running on each sample separately). You need write the main logic of this function, i.e. calculating the prediction for a single sample.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOLUTION CELL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class knn:\n",
    "    def __init__(self, k = 5, distance = euclidean_distance):\n",
    "        self.k = k\n",
    "        self.get_distance = distance  # Function to get used later.\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # There is no pre-processing done in KNN.\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "            \n",
    "    def predict(self, X):\n",
    "        # Handles lists/arrays containing multiple samples.\n",
    "        X = np.array(X)\n",
    "        if len(X.shape) >= 2:\n",
    "            return np.array([self.predict(x) for x in X])\n",
    "        # Get the distances between the given point and every training point,.\n",
    "        distances = [self.get_distance(X, x_train) for x_train in self.X_train]\n",
    "        # Sort the distances and take the closest (up to k points).\n",
    "        votes = [self.y_train[i] for i in np.argsort(distances)[:self.k]]\n",
    "        # Return the most common class from the top k points.\n",
    "        return most_common_class(votes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING CELL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: [-2.70900e+00  6.90000e-02  1.47200e+00  5.20000e+01  2.89500e+00\n",
      "  5.59694e+02]\n",
      "\tPredicted class: triclinic\n",
      "\tTrue class: orthorhombic\n",
      "Sample: [-2.7290e+00  1.2000e-02  2.9730e+00  2.2000e+01  2.8880e+00  2.5873e+02]\n",
      "\tPredicted class: monoclinic\n",
      "\tTrue class: orthorhombic\n",
      "Sample: [-2.08700e+00  1.18000e-01  1.49200e+00  3.10000e+01  3.23300e+00\n",
      "  3.71607e+02]\n",
      "\tPredicted class: monoclinic\n",
      "\tTrue class: triclinic\n",
      "Sample: [-2.64900e+00  6.70000e-02  5.84000e-01  1.60000e+01  2.58800e+00\n",
      "  1.75701e+02]\n",
      "\tPredicted class: monoclinic\n",
      "\tTrue class: monoclinic\n",
      "Sample: [-2.45300e+00  7.20000e-02  2.84000e+00  2.60000e+01  3.57900e+00\n",
      "  2.78304e+02]\n",
      "\tPredicted class: orthorhombic\n",
      "\tTrue class: orthorhombic\n",
      "Sample: [-2.75400e+00  5.10000e-02  3.22200e+00  2.20000e+01  2.75800e+00\n",
      "  2.67162e+02]\n",
      "\tPredicted class: monoclinic\n",
      "\tTrue class: monoclinic\n",
      "Sample: [-2.86800e+00  9.00000e-02  1.05500e+00  2.60000e+01  2.96300e+00\n",
      "  3.07264e+02]\n",
      "\tPredicted class: triclinic\n",
      "\tTrue class: triclinic\n",
      "The accuracy of the classifier is 0.515\n"
     ]
    }
   ],
   "source": [
    "# Initialise the classifier with k=3 (using 9 neigbours).\n",
    "classifier = knn(k=9)\n",
    "# Fit the classifier to the training set.\n",
    "classifier.fit(X_nd_train, y_nd_train)\n",
    "\n",
    "# Predict the classification for some samples to the testing set.\n",
    "for (sample, prediction, truth) in zip(X_nd_test[3:10], classifier.predict(X_nd_test[3:10]), y_nd_test[3:10]):\n",
    "    # Print the sample, predicted class and ground truth.\n",
    "    print(\"Sample: {}\\n\\tPredicted class: {}\\n\\tTrue class: {}\".format(sample, prediction, truth))\n",
    "    \n",
    "y_nd_pred = classifier.predict(X_nd_test)\n",
    "\n",
    "# calccualte the accuracy of the classifier\n",
    "accuracy = np.sum(y_nd_pred == y_nd_test) / len(y_nd_test)\n",
    "\n",
    "print(\"The accuracy of the classifier is {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "For the second part of the assignment, you are expected to implement a decision tree classifier. A decision tree models the data as a series of decisions based on the values of different features of the sample. The predictions are made in an interpretable fashion, where the decision is made by considering different sample features, and their values, until the new sample is grouped with similar samples presented during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1 - Entropy and Information Gain\n",
    "#### 10% marks\n",
    "\n",
    "Important concepts in decision trees are **entropy** and **information gain**. **Entropy** is a measure of the variance in the data, of how \"unpredictable\" the dataset is:\n",
    "\n",
    "- If a dataset consists only of samples with the same label (e.g. $\\{\\blacksquare,\\blacksquare,\\blacksquare,\\blacksquare,\\blacksquare,\\blacksquare\\}$), the entropy will be zero (the data is predictable).\n",
    "- If a dataset consists of an equal amount of samples from two classes, (e.g. $\\{\\blacksquare,\\triangle,\\triangle,\\blacksquare,\\triangle,\\blacksquare\\}$), the entropy will be one (the data is unpredictable).\n",
    "- If the class distribution in the dataset lies somewhere between these two extremes, the entropy will be between one and zero.\n",
    "- Entropy also increases as the number of different classes increases.\n",
    "\n",
    "Given $c$ classes, and their associated probabilities (frequencies) in the datasets, $p_i \\forall i \\in 0..c$, the entropy is calculated as:\n",
    "\n",
    "\\begin{equation*}\n",
    "E = -\\sum_i p_i log_2(p_i).\n",
    "\\end{equation*}\n",
    "\n",
    "Implement a function `entropy` which calculates the entropy of a set of class labels from the list of their associated probabilities:\n",
    "\n",
    "- `entropy(p_per_class)`: calculates the entropy of a set of class probabilities\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `p_per_class`: A list of $c$ probabilities, one for each class in the dataset. This either a list of length $c$, or a `numpy.array` of dimensions `(c,)`<br>\n",
    "\n",
    "    *Returns:*<br>\n",
    "    The entropy of a set with class probabilities given in `p_per_class`.<br>\n",
    "    \n",
    "    *Note:*<br>\n",
    "    You do not need to check if the list of probabilities given is correct; i.e. you may assume that all the probabilities in the list are strictly greater than zero, and that the sum of all the class probabilities equals one.\n",
    "    \n",
    "    *Example:*\n",
    "\n",
    "    ```python\n",
    "    probabilities = [0.5, 0.5]\n",
    "    print(entropy(probabilities))\n",
    "    ```\n",
    "    *Example output:*<br>\n",
    "    `1.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOLUTION CELL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(p_per_class):\n",
    "    return -np.sum([p * np.log2(p) for p in p_per_class])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING CELL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of a set with only one class: -0.0\n",
      "Entropy of a set with two equally probable classes: 1.0\n",
      "Entropy of a set with four equally probable clasess: 2.0\n",
      "Entropy of a set with four classes with different probabilities: 1.846\n",
      "Entropy of the numerical (batteries) dataset: 1.552\n",
      "Entropy of the categorical (forest cover) dataset: 1.739\n"
     ]
    }
   ],
   "source": [
    "print(\"Entropy of a set with only one class: {}\".format(entropy([1.0])))\n",
    "print(\"Entropy of a set with two equally probable classes: {}\".format(entropy([0.5, 0.5])))\n",
    "print(\"Entropy of a set with four equally probable clasess: {}\".format(entropy([0.25, 0.25, 0.25, 0.25])))\n",
    "print(\"Entropy of a set with four classes with different probabilities: {:.3f}\".format(\n",
    "    entropy([0.2, 0.3, 0.4, 0.1])))\n",
    "print(\"Entropy of the numerical (batteries) dataset: {:.3f}\".format(\n",
    "    entropy(list(class_probabilities(y_nd).values()))))\n",
    "print(\"Entropy of the categorical (forest cover) dataset: {:.3f}\".format(\n",
    "    entropy(list(class_probabilities(y_cd).values()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **information gain** describes how much variance was lost by dividing a set into parts, i.e. how much more \"predictable\" the parts are from the whole.\n",
    "\n",
    "For example, if we have a dataset $d=\\{\\blacksquare,\\triangle,\\triangle,\\blacksquare,\\triangle,\\blacksquare,\\triangle,\\blacksquare\\}$ (which is \"maximally unpredictable\", so we can calculate $E(d) = 1$), we can:\n",
    "- split it into $d_1=\\{\\blacksquare,\\blacksquare,\\blacksquare,\\blacksquare\\}$ and $d_2=\\{\\triangle, \\triangle, \\triangle, \\triangle\\}$.\n",
    "\n",
    "    Both of $d_1$ and $d_2$ are \"very predictable\" ($E(d_1) = E(d_2) = 0$), both subsets consist of one class only). The resulting information gain is large (we go from unpredictable to predictable, so we gain information):\n",
    "    \n",
    "    $I = E(d) - (0.5E(d_1) + 0.5E(d_2) = 1 - (0+0) =1$\n",
    "    \n",
    "- split it into $d_1=\\{\\blacksquare,\\triangle,\\triangle,\\blacksquare\\}$ and $d_2=\\{\\triangle,\\blacksquare,\\triangle,\\blacksquare\\}$.\n",
    "\n",
    "    Both of $d_1$ and $d_2$ are \"very unpredictable\" ($E(d_1) = E(d_2) = 1$), both subsets have the same amount of samples from each of the two classes). The resulting information gain is small (we start from an unpredictable dataset, and end with two unpredictable subsets, so we do not gain information):\n",
    "\n",
    "    $I = E(d) - (0.5E(d_1) + 0.5E(d_2) = 1 - (0.5\\times1+0.5\\times1) =0$\n",
    "    \n",
    "<br>\n",
    "In general, if we have a dataset $d$ containing $|d|$ samples, and we split it into $s$ subsets $d_i \\forall i=1..s$, each of size $|d_i|$, the information gain of this split is calculated as:\n",
    "\n",
    "\\begin{equation*}\n",
    "    I = E(d) - \\sum_{i=0}^s \\frac{|d_i|}{|d|}E(d_i)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2 - Decision Tree classifier\n",
    "#### 30% marks\n",
    "\n",
    "In each decision node of a decision tree, this classifier splits the dataset into two or more parts according to a value of a certain feature in the dataset.\n",
    "\n",
    "Given a set of M samples $\\mathbf{x} = \\{\\mathbf{x}_i\\} \\forall i=1..M$ with n features each $\\mathbf{x}_i = \\{x_{1,i}, \\dots, x_{n,i}\\}$, we could decide to split the dataset at the $j^{\\texttt{th}}$ (numerical) feature at value $v$. This would mean splitting the dataset into:\n",
    "- the subset $\\mathbf{x_{<}} = \\{\\mathbf{x}_i | x_{j,i} < v\\}$, which contains all the samples with the $j^{\\texttt{th}}$ smaller than $v$ and\n",
    "- the subset $\\mathbf{x_{\\geq}} = \\{\\mathbf{x}_i | x_{j,i} \\geq v\\}$, which contains all the samples with the $j^{\\texttt{th}}$ greater or equal than $v$.\n",
    "\n",
    "Similarly, we could decide to split a dataset at the $j^{\\texttt{th}}$ feature which is categorical. If the $j^{\\texttt{th}}$ feature of a sample $\\mathbf{x}_i$ can hold values $\\{\\texttt{child}, \\texttt{teen}, \\texttt{adult}\\}$, the resulting subsets would be:\n",
    "- the subset $\\mathbf{x_{\\texttt{child}}} = \\{\\mathbf{x}_i | x_{j,i} = \\texttt{child}\\}$, which contains all the samples with the feature $j^{\\texttt{th}}$ equal to $\\texttt{child}$, \n",
    "- the subset $\\mathbf{x_{\\texttt{teen}}} = \\{\\mathbf{x}_i | x_{j,i} = \\texttt{teen}\\}$, which contains all the samples with the feature $j^{\\texttt{th}}$ equal to $\\texttt{teen}$ and\n",
    "- the subset $\\mathbf{x_{\\texttt{adult}}} = \\{\\mathbf{x}_i | x_{j,i} = \\texttt{adult}\\}$, which contains all the samples with the feature $j^{\\texttt{th}}$ equal to $\\texttt{adult}$.\n",
    "\n",
    "In each node of the decision tree, the dataset is split according to the attribute $j$ which results in **the highest information gain** after the split. For categorical features, there is only one possible split (each category becomes a subset). For numerical features, it is neccessary to check all the possible values of split. For example, if the $j^{\\texttt{th}}$ in the dataset has appeared with the values of $\\{1, 1.5, 2.7, 3.2, 5\\}$, you need to calculate the information gain for splitting the dataset at $v=1.5$ (into $\\mathbf{x_{< 1.5}}$ and $\\mathbf{x_{\\geq 1.5}}$), $v=2.7$, $v=3.2$, $v=5$.\n",
    "\n",
    "The splitting continues until each node contains only samples of a single class, or a stopping criterion is reached. If a node contains training samples of more than one class, it returns the label of the majority (most probable) class as its decision.\n",
    "\n",
    "Implement a `DecisionTree` classifier which works on samples with both numerical and categorical features as a Python class implementing the following member functions:\n",
    "\n",
    "- `__init__(self, max_depth = -1, min_samples_per_node = 1)`: class constructor\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `max_dept` : The maximal depth of the tree (`max_depth == 0` corresponds to a decision tree with only the root node. `max_depth == -1` means no limit to the depth of the tree) <br>\n",
    "    `min_samples_per_node`: The minimal number of samples contained in a terminal (decision) node. If a split would cause one of the subsets to have less than `min_samples_per_node` samples, the split is not performed. <br><br>\n",
    "    \n",
    "- `fit(self, X, y)`: member function used to train the classifier (fit the model to the data)\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `X`: The dataset samples. This is either a list of $M$ lists of length $n$, or a `numpy.array` of dimensions `(M, n)`<br>\n",
    "    `y`: The dataset labels. This is either a list of length $M$, or a `numpy.array` of dimensions `(M,)`<br>\n",
    "    \n",
    "    *Returns:*<br>\n",
    "    The trained classifier model.<br><br>\n",
    "    \n",
    "- `predict(self, X)`: member function used to predict the classes of samples `X`\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `X`: The samples for which to predict a class. If this is a single sample, then `X` is either a list of length $n$, or a `numpy.array` of dimensions `(n,)`. If this is a set of samples, then `X` is either a list of $M$ lists of length $n$, or a `numpy.array` of dimensions `(M, N)`<br>\n",
    "    \n",
    "    *Returns:*<br>\n",
    "    Predicted class for the samples of X. If `X` was a single sample, then the output is a single class label. If `X` was a set of samples, then the output is a `numpy.array` of dimensions `(n,`)<br>\n",
    "    \n",
    "    *Note:*<br>\n",
    "    The provided code outline already handles the case where `X` is a set of samples (by running on each sample separately). You need write the main logic of this function, i.e. calculating the prediction for a single sample.<br><br>\n",
    "    \n",
    "*Note:* Your implementation will be tested in two parts. Firstly, it will be tested only on a dataset containing numerical values. Secondly, it will also be tested on a dataset containing a mix of categorical and numerical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOLUTION CELL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code modified from https://github.com/AssemblyAI-Examples/Machine-Learning-From-Scratch/tree/main/04%20Decision%20Trees\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None\n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=-1, min_samples_per_node=1, n_features=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_per_node = min_samples_per_node\n",
    "        self.n_features = n_features\n",
    "        self.root = None\n",
    "           \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Create and train the decision tree. Parameters are training data and\n",
    "        associated ground truth labels.\n",
    "        \"\"\"\n",
    "        self.n_features = X.shape[1] if not self.n_features else min(X.shape[1],self.n_features)\n",
    "        self.root = self._grow_tree(X, y)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        \"\"\"\n",
    "        Increases the size of the tree on both sides on the best feature found.\n",
    "        \"\"\"\n",
    "        n_samples, n_feats = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "\n",
    "        # Check stopping criteria.\n",
    "        if (n_labels == 1 or n_samples < self.min_samples_per_node or (depth >= self.max_depth and self.max_depth != -1)):\n",
    "            leaf_value = most_common_class(y)\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        feat_idxs = np.random.choice(n_feats, self.n_features, replace=False)\n",
    "        \n",
    "        # Find the best split.\n",
    "        best_feature, best_thresh = self._best_split(X, y, feat_idxs)\n",
    "\n",
    "        # Create child nodes / branches.\n",
    "        left_idxs, right_idxs = self._split(X[:, best_feature], best_thresh)\n",
    "        left = self._grow_tree(X[left_idxs, :], y[left_idxs], depth+1)\n",
    "        right = self._grow_tree(X[right_idxs, :], y[right_idxs], depth+1)\n",
    "        return Node(best_feature, best_thresh, left, right)\n",
    "\n",
    "\n",
    "    def _best_split(self, X, y, feat_idxs):\n",
    "        \"\"\"\n",
    "        Determines the best feature to split on.\n",
    "        \"\"\"\n",
    "        best_gain = -1\n",
    "        split_idx, split_threshold = None, None\n",
    "\n",
    "        for feat_idx in feat_idxs:\n",
    "            X_column = X[:, feat_idx]\n",
    "            thresholds = np.unique(X_column)\n",
    "\n",
    "            for thr in thresholds:\n",
    "                # calculate the information gain\n",
    "                gain = self._information_gain(y, X_column, thr)\n",
    "\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_idx = feat_idx\n",
    "                    split_threshold = thr\n",
    "\n",
    "        return split_idx, split_threshold\n",
    "\n",
    "\n",
    "    def _information_gain(self, y, X_column, threshold):\n",
    "        \"\"\"\n",
    "        Calculates the information gain from a split. Returns tuple of L and R\n",
    "        indexes for the split.\n",
    "        \"\"\"\n",
    "        # Parent entropy.\n",
    "        parent_entropy = self._entropy(y)\n",
    "        # Create children.\n",
    "        left_idxs, right_idxs = self._split(X_column, threshold)\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "        # Calculate the weighted average entropy of children.\n",
    "        n = len(y)\n",
    "        n_l, n_r = len(left_idxs), len(right_idxs)\n",
    "        e_l, e_r = self._entropy(y[left_idxs]), self._entropy(y[right_idxs])\n",
    "        child_entropy = (n_l/n) * e_l + (n_r/n) * e_r\n",
    "        # Calculate the information gain.\n",
    "        information_gain = parent_entropy - child_entropy\n",
    "        return information_gain\n",
    "\n",
    "    def _split(self, X_column, split_thresh):\n",
    "        \"\"\"\n",
    "        Splits the data.\n",
    "        \"\"\"\n",
    "        left_idxs = np.argwhere(X_column <= split_thresh).flatten()\n",
    "        right_idxs = np.argwhere(X_column > split_thresh).flatten()\n",
    "        return left_idxs, right_idxs\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Takes in multiple samples to be predicted. Returns the predicted class\n",
    "        of each sample in an array.\n",
    "        \"\"\"\n",
    "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        \"\"\"\n",
    "        Returns the predicted class of the given sample.\n",
    "        \"\"\"\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        return self._traverse_tree(x, node.right)\n",
    "\n",
    "    def _entropy(self, p_per_class):\n",
    "        \"\"\"\n",
    "        Returns the entropy given an ArrayLike of probabilites of each class occurance.\n",
    "        \"\"\"\n",
    "        return -np.sum([p * np.log2(p) for p in list(class_probabilities(p_per_class).values())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING CELLS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will test if the classifier implemented model can fit to the [numerical dataset](#Numerical-data), and predict solutions for some of the testing samples (this is not model evaluation yet):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: [-2.45500e+00  7.00000e-02  2.34400e+00  2.60000e+01  3.21300e+00\n",
      "  3.09993e+02]\n",
      "\tPredicted class: triclinic\n",
      "\tTrue class: orthorhombic\n",
      "Sample: [-2.35200e+00  8.30000e-02  1.36700e+00  2.80000e+01  2.93500e+00\n",
      "  3.57496e+02]\n",
      "\tPredicted class: monoclinic\n",
      "\tTrue class: orthorhombic\n",
      "Sample: [-2.55300e+00  7.30000e-02  2.64900e+00  3.20000e+01  2.87700e+00\n",
      "  3.73622e+02]\n",
      "\tPredicted class: monoclinic\n",
      "\tTrue class: monoclinic\n",
      "Sample: [-2.43900e+00  5.70000e-02  2.30000e-01  1.50000e+01  3.02400e+00\n",
      "  1.77312e+02]\n",
      "\tPredicted class: orthorhombic\n",
      "\tTrue class: triclinic\n",
      "Sample: [-2.88700e+00  4.00000e-02  3.14400e+00  5.20000e+01  2.69000e+00\n",
      "  6.79101e+02]\n",
      "\tPredicted class: monoclinic\n",
      "\tTrue class: monoclinic\n",
      "Sample: [-2.56400e+00  5.80000e-02  2.73000e+00  2.80000e+01  2.85600e+00\n",
      "  3.60121e+02]\n",
      "\tPredicted class: monoclinic\n",
      "\tTrue class: orthorhombic\n",
      "Sample: [-2.91100e+00  6.40000e-02  3.07900e+00  3.40000e+01  2.63300e+00\n",
      "  4.31422e+02]\n",
      "\tPredicted class: monoclinic\n",
      "\tTrue class: triclinic\n"
     ]
    }
   ],
   "source": [
    "# Initialise the classifier, requiring at least 3 samples in each node\n",
    "classifier = DecisionTree(min_samples_per_node = 3)\n",
    "# Fit the classifier to the training data\n",
    "classifier.fit(X_nd_train, y_nd_train)\n",
    "# Predict the classification for some samples to the testing set\n",
    "for (sample, prediction, truth) in zip(X_nd_test[3:10], classifier.predict(X_nd_test[3:10]), y_nd_test[3:10]):\n",
    "#for (sample, prediction, truth) in zip(X_nd_test, classifier.predict(X_nd_test), y_nd_test):\n",
    "    # Print the sample, predicted class and ground truth\n",
    "    print(\"Sample: {}\\n\\tPredicted class: {}\\n\\tTrue class: {}\".format(sample, prediction, truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will check if the dataset is able to fit the model to the [dataset with mixed numerical and categorical values](#Categorical-data), and predict solutions for some of the testing samples (this is not model evaluation yet):\n",
    "\n",
    "_**Warning:**_ Executing this cell may take a bit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: [2.4 48.0 11.0 0.0 0.0 0.4 224.0 215.0 123.0 1.3 'Cache_la_Poudre'\n",
      " 'ELU-2717']\n",
      "\tPredicted class: Ponderosa_Pine\n",
      "\tTrue class: Cottonwood/Willow\n",
      "Sample: [3.3 67.0 16.0 0.1 0.0 1.7 234.0 207.0 100.0 1.9 'Rawah' 'ELU-8772']\n",
      "\tPredicted class: Spruce/Fir\n",
      "\tTrue class: Spruce/Fir\n",
      "Sample: [3.3 60.0 15.0 0.1 -0.0 2.4 231.0 207.0 104.0 4.1 'Neota' 'ELU-8703']\n",
      "\tPredicted class: Spruce/Fir\n",
      "\tTrue class: Spruce/Fir\n",
      "Sample: [3.2 62.0 10.0 0.4 0.0 2.0 229.0 219.0 122.0 0.9 'Comanche_Peak'\n",
      " 'ELU-7755']\n",
      "\tPredicted class: Spruce/Fir\n",
      "\tTrue class: Spruce/Fir\n",
      "Sample: [2.9 121.0 6.0 0.5 0.1 3.6 230.0 235.0 139.0 3.1 'Rawah' 'ELU-4744']\n",
      "\tPredicted class: Lodgepole_Pine\n",
      "\tTrue class: Lodgepole_Pine\n",
      "Sample: [3.2 155.0 15.0 0.2 0.0 0.4 237.0 240.0 129.0 2.3 'Neota' 'ELU-4758']\n",
      "\tPredicted class: Spruce/Fir\n",
      "\tTrue class: Spruce/Fir\n",
      "Sample: [3.0 330.0 8.0 0.1 0.0 2.6 201.0 231.0 169.0 6.2 'Rawah' 'ELU-7745']\n",
      "\tPredicted class: Lodgepole_Pine\n",
      "\tTrue class: Spruce/Fir\n"
     ]
    }
   ],
   "source": [
    "# Initialise the classifier, requiring the decision tree to have no more than 5 levels\n",
    "classifier = DecisionTree(max_depth = 4)\n",
    "# Fit the classifier to the training data\n",
    "classifier.fit(X_cd_train, y_cd_train)\n",
    "\n",
    "# Predict the classification for some samples to the testing set\n",
    "for (sample, prediction, truth) in zip(X_cd_test[3:10], classifier.predict(X_cd_test[3:10]), y_cd_test[3:10]):\n",
    "    # Print the sample, predicted class and ground truth\n",
    "    print(\"Sample: {}\\n\\tPredicted class: {}\\n\\tTrue class: {}\".format(sample, prediction, truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation and analysis\n",
    "\n",
    "Executing all the cells from the previous section correctly only means that your implementation of [kNN classifier](#knn-Classifier) and [Decision Tree classifier](#Decision-Tree-classifier) runs on the provided data. This has still not provided any insight on how well those models represent the data.\n",
    "\n",
    "In this section, you are instead required to calculate some evaluation metrics, and evaluate the produced models on the whole of the held-out data (test set) defined in the [Dataset](#Dataset) section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.1 - Evaluation\n",
    "#### 10% marks\n",
    "\n",
    "You are required to write a function that will calculate different evaluation metrics based on the ground truth labels and the predicted labels. Specifically, write a function:\n",
    "- `evaluate(y_true, y_pred)`: evaluate classification results\n",
    "\n",
    "    *Inputs:*<br>\n",
    "    `y_true` : Ground truth labels for $n$ samples. This is either a list of $n$ elements, or a `numpy.array` of dimensions `(n,)`\n",
    "    `y_pred` : Predicted labels for $n$ samples. This is either a list of $n$ elements, or a `numpy.array` of dimensions `(n,)`\n",
    "    \n",
    "    *Returns:*<br>\n",
    "    A touple `(a, p, r, k)` consisting of the following values:\n",
    "    - `a` : overall accuracy of the predictions\n",
    "    - `p` : a dictionary containing a precision score for each class present in `y_true`\n",
    "    - `r` : a dictionary containing a recall score for each class present in `y_true`\n",
    "    - `k` : Cohen's Kappa metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOLUTION CELL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def evaluate(y_true, y_pred):\n",
    "    labels = list(np.unique(y_true))\n",
    "    accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "    precision = metrics.precision_score(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        average=None,\n",
    "        labels=labels\n",
    "    )\n",
    "    precision_dict = dict(zip(labels, precision))\n",
    "    recall = metrics.recall_score(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        average=None,\n",
    "        labels=labels\n",
    "    )\n",
    "    recall_dict = dict(zip(labels, recall))\n",
    "    cohen_kappa = metrics.cohen_kappa_score(y_true, y_pred)\n",
    "    return accuracy, precision_dict, recall_dict, cohen_kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING CELL:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell evaluates your implementation of [kNN classifier](#Task-2.2---kNN-classifier) and [Decision Tree classifier](#Task-3.2---Decision-Tree-classifier) on the numerical dataset defined in the [Dataset](#Dataset) section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating numerical dataset, using kNN:\n",
      "Accuracy = 0.5625, Cohen's Kappa = 0.3316\n",
      "\tClass monoclinic: precision = 0.52, recall = 0.75\n",
      "\tClass orthorhombic: precision = 0.62, recall = 0.50\n",
      "\tClass triclinic: precision = 0.56, recall = 0.42\n",
      "Evaluating numerical dataset, using DecisionTree:\n",
      "Accuracy = 0.5000, Cohen's Kappa = 0.2361\n",
      "\tClass monoclinic: precision = 0.43, recall = 0.62\n",
      "\tClass orthorhombic: precision = 0.56, recall = 0.45\n",
      "\tClass triclinic: precision = 0.56, recall = 0.42\n"
     ]
    }
   ],
   "source": [
    "classifier_knn = knn(k=5)\n",
    "classifier_knn.fit(X_nd_train, y_nd_train)\n",
    "\n",
    "classifier_dt = DecisionTree(min_samples_per_node = 3)\n",
    "classifier_dt.fit(X_nd_train, y_nd_train)\n",
    "\n",
    "y_knn = classifier_knn.predict(X_nd_test)\n",
    "y_dt = classifier_dt.predict(X_nd_test)\n",
    "\n",
    "a_knn, p_knn, r_knn, k_knn = evaluate(y_nd_test, y_knn)\n",
    "a_dt, p_dt, r_dt, k_dt = evaluate(y_nd_test, y_dt)\n",
    "\n",
    "print(\"Evaluating numerical dataset, using kNN:\")\n",
    "print(\"Accuracy = {:.4f}, Cohen's Kappa = {:.4f}\".format(a_knn, k_knn))\n",
    "for key in p_knn.keys():\n",
    "    print(\"\\tClass {}: precision = {:.2f}, recall = {:.2f}\".format(key, p_knn[key], r_knn[key]))\n",
    "\n",
    "print(\"Evaluating numerical dataset, using DecisionTree:\")\n",
    "print(\"Accuracy = {:.4f}, Cohen's Kappa = {:.4f}\".format(a_dt, k_dt))\n",
    "for key in p_dt.keys():\n",
    "    print(\"\\tClass {}: precision = {:.2f}, recall = {:.2f}\".format(key, p_dt[key], r_dt[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell evaluates your implementation of [Decision Tree classifier](#Decision-Tree-classifier) on the [dataset containing a mixture of numerical and categorical data](#Categorical-data):\n",
    "\n",
    "_**Warning:**_ Executing this cell may take a bit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating categorical dataset, using DecisionTree:\n",
      "Accuracy = 0.6987, Cohen's Kappa = 0.5061\n",
      "\tClass Aspen: precision = 0.00, recall = 0.00\n",
      "\tClass Cottonwood/Willow: precision = 0.00, recall = 0.00\n",
      "\tClass Douglas-fir: precision = 0.46, recall = 0.05\n",
      "\tClass Krummholz: precision = 0.68, recall = 0.52\n",
      "\tClass Lodgepole_Pine: precision = 0.74, recall = 0.75\n",
      "\tClass Ponderosa_Pine: precision = 0.64, recall = 0.86\n",
      "\tClass Spruce/Fir: precision = 0.67, recall = 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bennicholls/opt/anaconda3/envs/spark/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "classifier_categorical = DecisionTree(max_depth = 4)\n",
    "classifier_categorical.fit(X_cd_train, y_cd_train)\n",
    "\n",
    "y_cd_pred = classifier_categorical.predict(X_cd_test)\n",
    "a_cat, p_cat, r_cat, k_cat = evaluate(y_cd_test, y_cd_pred)\n",
    "\n",
    "print(\"Evaluating categorical dataset, using DecisionTree:\")\n",
    "print(\"Accuracy = {:.4f}, Cohen's Kappa = {:.4f}\".format(a_cat, k_cat))\n",
    "for key in p_cat.keys():\n",
    "    print(\"\\tClass {}: precision = {:.2f}, recall = {:.2f}\".format(key, p_cat[key], r_cat[key]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.2 - Analysis\n",
    "#### 10% marks\n",
    "\n",
    "Answer the following questions in the space provided below (marked as **YOUR ANSWERS**):\n",
    "1. Explain the difference between the different performance metrics calculated for [Task 4.1](#Task-4.1---Evaluation). Which additional metrics could you propose to evaluate the performance of the defined models? Which of the calculated metrics would you chose to report, and why, for the analysis of the two [datasets](#Datasets) used in this assessment?\n",
    "\n",
    "2. In case you were handling a _very large_ amount of data, which of the models do you expect to be larger (i.e. take up more memory)? Which of the models do you expect to train faster? Which of the models do you expect to reach a decision faster? Explain and justify your answers.\n",
    "\n",
    "3. When handling numerical data, what is the role of normalisation? The numerical data used in this assessment was not normalised. If you were to normalise the data before training these classification models, would either of them change how they represent the data (and potentially return different results)?\n",
    "\n",
    "4. For evaluating the performance of the classifiers implemented for this assignment, $80\\%$ of the data was used for training the models, and $20\\%$ for testing. What are the shortcomings of this evaluation strategy, and can you propose and describe a better one?\n",
    "\n",
    "_Note:_ You may use the cell marked as **EXPERIMENTAL CELL** to write any code that could help you answer the above questions, or in general, to experiment with the code produced for this assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPERIMENTAL CELL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ You may use this cell to write any code which may help you answers the questions above ##############\n",
    "####### Your implementations from this cell will not be assessed, feel free to use it for experimentation ########"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### YOUR ANSWERS:\n",
    "\n",
    "1. Accuracy measures the proportion of correct predictions out of all of the predictions made and can be misleading if the distribution of classes is imbalanced. Precision checks how many positive predictions were truly positive  a high precision likely means the classifier will make fewer positive predictions but with a higher degree of confidence. Recall measures the proportion of true positive predictions out of all the actual positives. Recall is a measure of sensitivity where it will make more positive predictions but with a higher rate of false positives. Cohens Kappa is a good measure where there is class imbalance and measures agreement between the classifier and true values.\n",
    "\n",
    "Other metrics that could be used include F1 Score, Root Mean Squared Error (RMSE), or Gini Index. F1 Score is a mix of precision and recall and can be used to combine the two into a single value metric. RMSE is an alternative for accuracy where deviation of predictions from the true values is measured. Gini Index is mostly used in decision trees and it is a representation of variance.\n",
    "\n",
    "For reporting I would like to include all the calculated metrics as that data is important in some way and shows how well the classifier is working. The most important metric, in my opinion, is accuracy. Accuracy, as simple as it is, shows the overall effectiveness of the model  a higher precision is useless if the accuracy is low. \n",
    "\n",
    "\n",
    "2. With a very large volume of data the Decision Tree will have a higher memory usage as the tree itself as the tree has to be stored. Whilst many distances in KNN are also stored, this would work out to be less than the Decision Tree. KNN has no training time O(1) whereas a Decision Tree is O(n^2). KNN will take a long time to reach a decision (O(n)) as all points must be considered, whereas a Decision Tree will reach a decision in O(log n) time  this is due to the Decision Tree generalising the data in the fitting stage. This means for a single query KNN will produce a faster result whereas for multiple queries a Decision Tree would be faster long term after the initial fit.\n",
    "\n",
    "\n",
    "3. Data normalisation helps to clean the data and express it with a similar distribution across the board. I would expect the accuracy of for both to increase as there are a couple of larger values within the datasets that could overwhelm the Euclidean distance calculation; for example, the volume within the batteries dataset and the three hill shade values within the forest cover dataset where all of these values are over one hundred whereas other values within the datasets are less than one. \n",
    "\n",
    "\n",
    "4. An 80:20 training/test data split is common in machine learning tasks where one considerable drawback is that the performance of the models can be highly dependent on the specific split of the data; datasets with some infrequent classes or outliers then fitting the model to the data may produce unwanted results. A better evaluation strategy is k-fold cross validation or go even further and use leave-one-out cross validation. In leave-one-out cross validation, instead of using k folds, the data is used to train the model one time for each item in the set, using all other items as a training set and only one item as the testing set. This will give a model performance metric which is more robust to outliers in the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "1893493f561a40c1d916ca23d024f274e94c492e790a062517a35679f0fe3152"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
